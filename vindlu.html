<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  VindLU: A Recipe for Effective Video-and-Language Pretraining - Feng Cheng
  
  </title>
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-3SP0SC55LM"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-3SP0SC55LM');
  </script>
  <link href="atom.xml" rel="alternate" title="Feng Cheng" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:klauscc.github.io ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="Feng_Cheng.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_blank" href="https://drive.google.com/file/d/1xe6mJG6NuP58IrsOMw4liUaqeShJyklb/view?usp=sharing">Resume</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; Feng Cheng</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="Feng_Cheng.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_blank" href="https://drive.google.com/file/d/1xe6mJG6NuP58IrsOMw4liUaqeShJyklb/view?usp=sharing">Resume</a></li>
        

    <li><label>Categories</label></li>

         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		var currentURL = 'vindlu.html';
		currentURL = currentURL.substr(0,currentURL.length-5);
		$('#menu_item_'+currentURL).addClass('is_active');
	});
</script>
<div class="row">

    <div id="single-page-wrap">
        <h1>VindLU: A Recipe for Effective Video-and-Language Pretraining</h1>

        <div class="markdown-body post-page">
        <p><div style="text-align: center;"> <a href="https://klauscc.github.io">Feng Cheng</a><sup>1</sup> , <a href="">Xizi Wang</a><sup>2</sup> , <a href="https://jayleicn.github.io/">Jie Lei</a><sup>1</sup> , <a href="https://luddy.indiana.edu/contact/profile/?David_Crandall">David Crandall</a><sup>2</sup> , <a href="http://www.cs.unc.edu/%7Embansal/">Mohit Bansal</a><sup>1</sup> , <a href="https://www.gedasbertasius.com/">Gedas Bertasius</a><sup>1</sup><br/>
<sup>1</sup> University of North Carolina at Chapel Hill, <sup>2</sup> Indiana University<br/>
CVPR 2023</p>

<p><button name="button1" onclick="location.href='https://arxiv.org/abs/2212.05051';"> arxiv </button> <button name="button2" onclick="location.href='https://github.com/klauscc/VindLU';"> Code </button></p>

<p><img src="media/16700216415652/16807109507588.jpg" alt=""/></p>

<h2 id="toc_0">Abstract</h2>

<p><div style="text-align: justify;"><br/>
The last several years have witnessed remarkable progress in video-and-language (VidL) understanding. However, most modern VidL approaches use complex and specialized model architectures and sophisticated pretraining protocols, making the reproducibility, analysis and comparisons of these frameworks difficult. Hence, instead of proposing yet another new VidL model, this paper conducts a thorough empirical study demystifying the most important factors in the VidL model design. Among the factors that we investigate are (i) the spatiotemporal architecture design, (ii) the multimodal fusion schemes, (iii) the pretraining objectives, (iv) the choice of pretraining data, (v) pretraining and finetuning protocols, and (vi) dataset and model scaling. Our empirical study reveals that the most important design factors include: temporal modeling, video-to-text multimodal fusion, masked modeling objectives, and joint training on images and videos. Using these empirical insights, we then develop a step-by-step recipe, dubbed VindLU, for effective VidL pretraining. Our final model trained using our recipe achieves comparable or better than state-of-the-art results on several VidL tasks without relying on external CLIP pretraining. In particular, on the text-to-video retrieval task, our approach obtains 61.2% on DiDeMo, and 55.0% on ActivityNet, outperforming current SOTA by 7.8% and 6.1% respectively. Furthermore, our model also obtains state-of-the-art video question-answering results on ActivityNet-QA, MSRVTT-QA, MSRVTT-MC and TVQA.</p>

<h2 id="toc_1">Key Findings</h2>

<ul>
<li><strong>Temporal Modeling</strong> leads to a significant improvement over the spatial-only baselines. Temporal Attention leads to <strong>+6%</strong> averaged video retrieval Top-1, 5, 10 accuracy on MSR-VTT, DiDeMo and ActivityNet datasets.</li>
<li><strong>Multimodal fusion</strong> that incorporates video features into text is critical for good VidL performance (+3.6%). Conversely, we find that adding text features to the video representation is not useful.</li>
<li><strong>Masked Language Modeling (MLM) objective</strong> significantly improves performance (<strong>+6.2%</strong>). However, to obtain such gains, a BERT-like language model pretrained on this objective is needed for initialization. Masked video modeling objective brings an additional <strong>+1%</strong> improvement.</li>
<li><strong>Pretraining jointly</strong> on images and videos is beneficial (<strong>+2.7%</strong>). Also, contrary to prior methods, we find <strong>multi-stage training unnecessary</strong>.</li>
<li><strong>Pretraining with a small number of frames (e.g., 4) is sufficient</strong> and it can significantly reduce the computational cost of large-scale pretraining. Pretraining with more frames does not lead to a substantial performance boost.</li>
<li>Compared to many recent CLIP-based VidL approaches, our recipe achieves comparable or even better performance with <strong>20\(\times\)</strong> less pretraining data.</li>
</ul>

<h2 id="toc_2">Experiments</h2>

<p>Based on our VindLU recipe, we achieve state-of-the-art results on 9 VidL benchmarks. See the recipe details in threads below. To highlight, on the text-to-video retrieval task, we outperform the state-of-the-arts by 7.8% and 6.1% on DiDeMo and ActivityNet.<br/>
<img src="media/16700216415652/16808045617909.jpg" alt=""/><br/>
<p float="top"><br/>
  <img src="media/16700216415652/16808053018796.jpg" width="48%" /> <img src="media/16700216415652/16808053115089.jpg" width="48%" /><br/>
</p></p>

<h2 id="toc_3">BibTex</h2>

<pre><code>@article{cheng2022vindlu,
  title={VindLU: A Recipe for Effective Video-and-Language Pretraining},
  author={Cheng, Feng and Wang, Xizi and Lei, Jie and Crandall, David and Bansal, Mohit and Bertasius, Gedas},
  journal={arXiv preprint arXiv:2212.05051},
  year={2022}
}
</code></pre>

        </div>
    </div>
</div>              
 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
