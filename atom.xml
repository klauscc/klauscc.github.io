<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Feng Cheng]]></title>
  <link href="https://klauscc.github.io/atom.xml" rel="self"/>
  <link href="https://klauscc.github.io/"/>
  <updated>2024-09-30T10:00:24-07:00</updated>
  <id>https://klauscc.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Feng Cheng]]></title>
    <link href="https://klauscc.github.io/Feng_Cheng.html"/>
    <updated>2018-10-21T20:23:35-07:00</updated>
    <id>https://klauscc.github.io/Feng_Cheng.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">About me</h2>

<p>I am currently a Ph.D student in Department of Computer Science at UNC at Chapel Hill, advised by Prof. <a href="https://www.gedasbertasius.com">Gedas Bertasius</a>. My current research interests lie in multimodal video understanding, including video-language (VidL) pretraining, video LLM, video continual learning, and video generation.</p>

<p>Prior to joining Gedas&#39;s Group, I worked with Prof. <a href="https://scholar.google.com/citations?user=v6VYQC8AAAAJ&amp;hl=en">Dinggang Shen</a> and Prof. <a href="https://scholar.google.com/citations?user=QGdnthwAAAAJ&amp;hl=en">Pew-Thian Yap</a> at UNC on medical imaging. I obtained both my B.S. degree in Information Security in 2016 and M.S. degree in ECE in 2019 at Shanghai JiaoTong University. During my M.S. study, I worked with Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=8tg3mv0AAAAJ&amp;view_op=list_works">Shilin Wang</a>.</p>

<p><span style="color:red"><strong>I am available in the job market and actively seeking opportunities. Please don&#39;t hesitate to reach out if you&#39;re interested.</strong></span></p>

<!--#### News
- 10/2022: Received a post-internship fellowship from Amazon.-->

<h2 id="toc_1">Experiences</h2>

<ul>
<li><strong>2023 /01 ~ Current</strong> Visiting Researcher at Meta FAIR. 
Mentor: <a href="https://scholar.google.com/citations?user=ss8KR5gAAAAJ&amp;hl=en&amp;pagesize=1000&amp;sortby=pubdate">Lorenzo Torresani</a></li>
<li><strong>2022 /05 ~ 2022 /08</strong> Applied Scientist Intern at Amazon AWS AI.<br/>
Mentor: <a href="https://scholar.google.com/citations?user=c8WhHZkAAAAJ&amp;hl=en">Bing Shuai</a> &amp; <a href="https://scholar.google.com/citations?user=KNcECJQAAAAJ&amp;hl=en">Mingze Xu</a></li>
<li><strong>2021 /05 ~ 2021 /08</strong> Applied Scientist Intern at Amazon AWS AI. 
Mentor: <a href="https://scholar.google.com/citations?user=KNcECJQAAAAJ&amp;hl=en">Mingze Xu</a> &amp; <a href="https://scholar.google.com/citations?user=ojKsx6AAAAAJ&amp;hl=en">Yuanjun Xiong</a></li>
</ul>

<h2 id="toc_2">Publications</h2>

<p>Check recent publications on my <a href="https://scholar.google.com/citations?hl=en&amp;user=L5WbA3EAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Google Scholar</a>.</p>

<ul>
<li><p><a href="">4DIFF: 3D-Aware Diffusion Model for Third-to-First Viewpoint Translation</a><br/>
<strong>Feng Cheng</strong>, Mi (Romy) Luo, Huiyu Wang, Alex Dimakis, Lorenzo Torresani, Gedas Bertasius, Kristen Grauman<br/>
<strong>ECCV 2024</strong></p></li>
<li><p><a href="https://arxiv.org/abs/2403.08755">DAM: Dynamic Adapter Merging for Continual Video QA Learning</a><br/>
<strong>Feng Cheng</strong>, Ziyang Wang, Yi-Lin Sung, Yan-Bo Lin, Mohit Bansal, Gedas Bertasius<br/>
<strong>Preprint</strong>  [<a href="https://github.com/klauscc/DAM">code</a>]</p></li>
<li><p><a href="https://arxiv.org/abs/2301.08237">Loconet: Long-short context network for active speaker detection</a><br/>
Xizi Wang, <strong>Feng Cheng</strong>, Gedas Bertasius, David Crandall<br/>
<strong>CVPR 2024</strong>  [<a href="https://github.com/SJTUwxz/LoCoNet_ASD">code</a>] </p></li>
<li><p><a href="https://arxiv.org/abs/2311.18259">Ego-exo4d: Understanding Skilled Human Activity from First-and Third-Person Perspectives</a><br/>
Kristen Grauman, Andrew Westbury, Lorenzo Torresani, Kris Kitani,<br/>
<strong>Feng Cheng</strong>, ... , Michael Wray<br/>
<strong>CVPR 2024</strong> (<span style="color:red"><strong>Oral</strong></span>) [<a href="https://ego-exo4d-data.org/">project website</a>] [<a href="https://t.co/rsVFZsbapM">blog</a>] [<a href="https://t.co/5c57sIibev">video</a>]</p></li>
<li><p><a href="https://arxiv.org/abs/2309.10091">Unified Coarse-to-Fine Alignment for Video-Text Retrieval</a><br/>
Ziyang Wang, Yi-Lin Sung, <strong>Feng Cheng</strong>, Gedas Bertasius, Mohit Bansal<br/>
<strong>ICCV 2023</strong> [<a href="https://github.com/Ziyang412/UCoFiA">Code</a>]</p></li>
<li><p><a href="https://arxiv.org/abs/2212.05051">VindLU: A Recipe for Effective Video-and-Language Pretraining</a><br/>
<strong>Feng Cheng</strong>, Xizi Wang, Jie Lei, David Crandall, Mohit Bansal, Gedas Bertasius<br/>
<strong>CVPR 2023</strong> [<a href="https://github.com/klauscc/VindLU">Code</a>]</p></li>
<li><p><a href="https://arxiv.org/abs/2204.01680">TALLFormer: Temporal Action Localization with Long-memory Transformer</a> <br/>
<strong>Feng Cheng</strong>, Gedas Bertasius <br/>
<strong>ECCV 2022</strong> [<a href="https://github.com/klauscc/TALLFormer">Code</a>]</p></li>
<li><p><a href="https://arxiv.org/abs/2203.16755">Stochastic Backpropagation: A Memory Efficient Strategy for Training Video Models</a> <br/>
<strong>Feng Cheng</strong>, Mingze Xu, Yuanjun Xiong, Hao Chen, Xinyu Li, Wei Li, Wei Xia<br/>
<strong>CVPR 2022</strong> (<span style="color:red"><strong>Oral</strong></span>) [<a href="https://github.com/amazon-research/stochastic-backpropagation">Code</a>]</p></li>
<li><p><a href="https://ieeexplore.ieee.org/document/9926190">High-Resolution 3D Magnetic Resonance Fingerprinting With a Graph Convolutional Network</a><br/>
<strong>Feng Cheng</strong>, Yilin Liu, Yong Chen, Pew-Thian Yap<br/>
<strong>IEEE Transactions on Medical Imaging (2022)</strong></p></li>
<li><p><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Spatio-Temporal_Fusion_Based_Convolutional_Sequence_Learning_for_Lip_Reading_ICCV_2019_paper.pdf">Spatio-Temporal Fusion based Convolutional Sequence Learning for Lip Reading</a> <br/>
Xingxuan Zhang, <strong>Feng Cheng</strong>, and Shi-Lin Wang <br/>
<strong>ICCV 2019</strong></p></li>
</ul>

<!--- [Submillimeter 3D MR Fingerprinting with Whole-Brain Coverage via Dual-Domain Deep Learning Reconstruction](https://www.ismrm.org/21/program-files/TeaserSlides/TeasersPresentations/0170-Teaser.html) 
**Feng Cheng**, Yong Chen and Pew-Thian Yap 
**ISMRM 2021**. (<span style="color:red">**Oral**</span>, “magna cum laude” award)-->

<ul>
<li><a href="https://link.springer.com/chapter/10.1007/978-3-030-59713-9_16">Acceleration of High-Resolution 3D MR Fingerprinting via a Graph Convolutional Network</a><br/>
<strong>Feng Cheng</strong>, Yong Chen, Xiaopeng Zong, Weili Lin, Pew-Thian Yap,
Dinggang Shen<br/>
<strong>MICCAI 2020</strong></li>
</ul>

<!--- [Visual speaker authentication with random prompt texts by a dual-task CNN framework](https://www.sciencedirect.com/science/article/abs/pii/S0031320318302152)
**Feng Cheng**, Shi-Lin Wang, and Alan Wee-Chung Liew.
**Pattern Recognition 2018**-->

<!--## Honors
- **2016** **First prize** of the Ninth National Information Security Competition
- **2016** **Second Prize** of the 13th Huawei Cup National Graduate Mathematical Modeling Contest
- **2017** Wenyuan Pan scholarship (**7000 RMB**)
- **2018** National Cyberspace safety scholarship(**50000 RMB**)-->

]]></content>
  </entry>
  
</feed>
